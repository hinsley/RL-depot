{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TDc4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM+4REVH9iECVC++IVV26GI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hinsley/RL-depot/blob/master/temporal-difference/TDc4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoWS52M9akHK",
        "colab_type": "text"
      },
      "source": [
        "# TDc4\n",
        "\n",
        "Temporal-difference learning for Connect 4\n",
        "\n",
        "Uses logistic NTD2(0) search algorithm described in [this paper](https://link.springer.com/article/10.1007/s10994-012-5280-0)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-FC5gTe8lY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import collections\n",
        "import math\n",
        "import multiprocessing as mp\n",
        "import time\n",
        "import torch\n",
        "from random import choice, choices\n",
        "from typing import Counter, List, Tuple, Union"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-_ek-5z_aN9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VALUE_BLANK = 0\n",
        "VALUE_X = 1\n",
        "VALUE_O = 2\n",
        "\n",
        "BOARD_SIZE = (6, 7) # Rows x Cols"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8h0zw6esVt2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ActiveFeatures = Counter[Union[Tuple[int, int, int, int],\n",
        "                               Tuple[int, int, int, int, int]]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZQjlqUxnNcv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Hyperparameter Configuration\n",
        "\n",
        "LEARNING_RATE =  1.0#@param {type: \"number\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uM-2YsQjk93",
        "colab_type": "text"
      },
      "source": [
        "### Quantity of Location-Independent Features\n",
        "\n",
        "For a given feature size $n \\times n$, the quantity of features in the equivalence class constructed by horizontally mirroring features is given by the following function $f_{LI}$, depending on the number $s$ of possible states per board position:\n",
        "\n",
        "$f_{LI}(n) = \\frac{s^{n^2} + s^n}{2} - 1$.\n",
        "\n",
        "We subtract $1$ from $f_{LI}$ because the single feature with all blank position states in each set of features with a given size is \"neutral\".\n",
        "\n",
        "In *Connect 4*, there are 3 possible position states. Combining each feature size $n \\times n$ for $1 \\leq n \\leq 4$, we find there are a total of $21,533,300$ features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S44dF146mi3J",
        "colab_type": "text"
      },
      "source": [
        "### Quantity of Location-Dependent Features\n",
        "\n",
        "For a given feature size $n \\times n$, the quantity of features in the equivalence class constructed by horizontally mirroring the entire board is given by the following function $f_{LD}$, depending on the number $s$ of possible states per board position:\n",
        "\n",
        "$f_{LD}(n) = s^{n^2} \\cdot (7-n) \\cdot \\left(4-\\left\\lfloor\\frac{n}{2}\\right\\rfloor\\right) - 1$.\n",
        "\n",
        "Again we subtract $1$ from $f_{LD}$ here due to an all-blank feature being \"neutral\".\n",
        "\n",
        "Combining each feature size $n \\times n$ for $1 \\leq n \\leq 4$, we find there are a total of $258,517,805$ features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDYQRWX-ugtj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "manager = mp.Manager()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBthCMUtOOFd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_FEATURE_SIZE = 6\n",
        "\n",
        "# Feature size (0 ... MAX_FEATURE_SIZE - 1) -> Row (0-indexed) -> Col (0-indexed) -> Encoding -> weight\n",
        "weights = manager.list()\n",
        "for feature_size in range(MAX_FEATURE_SIZE):\n",
        "  rows = manager.dict()\n",
        "  for row in range(BOARD_SIZE[0] - feature_size + 1):\n",
        "    rows[row] = manager.dict()\n",
        "    for col in range(math.ceil(BOARD_SIZE[1] / 2) - feature_size // 2):\n",
        "      rows[row][col] = manager.dict()\n",
        "  weights.append(rows)\n",
        "weights = [{row: {col: dict() for col in range(math.ceil(BOARD_SIZE[1] / 2) - feature_size // 2)} for row in range(BOARD_SIZE[0] - feature_size + 1)} for feature_size in range(MAX_FEATURE_SIZE)]\n",
        "# Location independent.\n",
        "for feature_size in range(MAX_FEATURE_SIZE):\n",
        "  weights[feature_size][-1] = manager.dict()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTfbMF7cLWXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def empty_board() -> torch.ByteTensor:\n",
        "  return torch.ones(BOARD_SIZE, dtype=torch.uint8) * VALUE_BLANK"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjsAmSOL-tbj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def game_over(state: torch.ByteTensor,\n",
        "              last_move_pos: Tuple[int, int]) -> bool:\n",
        "  # This does NOT check for draws.\n",
        "\n",
        "  last_move = state[last_move_pos]\n",
        "  lm_row = last_move_pos[0]\n",
        "  lm_col = last_move_pos[1]\n",
        "  \n",
        "  for start_offset in range(-3, 1):\n",
        "    # Check for horizontal wins.\n",
        "    try:\n",
        "      accumulator = 0\n",
        "      for i in range(4):\n",
        "        col = lm_col + start_offset + i\n",
        "        if col < 0 or col >= BOARD_SIZE[1]:\n",
        "          break\n",
        "        if last_move == state[lm_row, col]:\n",
        "          accumulator += 1\n",
        "      if accumulator == 4:\n",
        "        return True\n",
        "    except IndexError:\n",
        "      pass\n",
        "\n",
        "    # Check for vertical wins.\n",
        "    try:\n",
        "      accumulator = 0\n",
        "      for i in range(4):\n",
        "        row = lm_row + start_offset + i\n",
        "        if row < 0 or row >= BOARD_SIZE[0]:\n",
        "          break\n",
        "        if last_move == state[row, lm_col]:\n",
        "          accumulator += 1\n",
        "      if accumulator == 4:\n",
        "        return True\n",
        "    except IndexError:\n",
        "      pass\n",
        "    \n",
        "    # Check for diagonal (backslash direction) wins.\n",
        "    try:\n",
        "      accumulator = 0\n",
        "      for i in range(4):\n",
        "        row = lm_row + start_offset + i\n",
        "        col = lm_col + start_offset + i\n",
        "        if row < 0 or col < 0 or row >= BOARD_SIZE[0] or col >= BOARD_SIZE[1]:\n",
        "          break\n",
        "        if last_move == state[row, col]:\n",
        "          accumulator += 1\n",
        "      if accumulator == 4:\n",
        "        return True\n",
        "    except IndexError:\n",
        "      pass\n",
        "\n",
        "    # Check for diagonal (forward slash direction) wins.\n",
        "    try:\n",
        "      accumulator = 0\n",
        "      for i in range(4):\n",
        "        row = lm_row + start_offset + i\n",
        "        col = lm_col + start_offset + 4 - i\n",
        "        if row < 0 or col < 0 or row >= BOARD_SIZE[0] or col >= BOARD_SIZE[1]:\n",
        "          break\n",
        "        if last_move == state[row, col]:\n",
        "          accumulator += 1\n",
        "      if accumulator == 4:\n",
        "        return True\n",
        "    except IndexError:\n",
        "      pass\n",
        "  \n",
        "  return False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6riEImpPgEtQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def board_full(state: torch.ByteTensor) -> bool:\n",
        "  return (state != VALUE_BLANK).all()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66iXm8X1hIfx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pprint(state: torch.ByteTensor):\n",
        "  \"\"\" Displays a given game configuration. \"\"\"\n",
        "  def rasterize_position(position_state: int) -> str:\n",
        "    return {\n",
        "        VALUE_BLANK: \" \",\n",
        "        VALUE_X: \"X\",\n",
        "        VALUE_O: \"O\",\n",
        "    }[position_state]\n",
        "\n",
        "  print(\" __ _ _ _ _ _ __\")\n",
        "  for i, row in enumerate(state):\n",
        "    print(f\"\"\"{i+1}|{' '.join([rasterize_position(position_state.item()) for\n",
        "                              position_state in\n",
        "                              row])}|\"\"\")\n",
        "  print(\" -- - - - - - --\")\n",
        "  print(\"  A B C D E F G \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JUAPKwH_nRd",
        "colab_type": "code",
        "outputId": "7485e040-870e-4e07-bdb2-8f6c2f33b950",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\"\"\"\n",
        " __ _ _ _ _ _ __\n",
        "1|  X X        |\n",
        "2|  O O        |\n",
        "3|  O X   X O X|\n",
        "4|  O X   O X O|\n",
        "5|O X O   X O O|\n",
        "6|X O X   X O X|\n",
        " -- - - - - - --\n",
        "  A B C D E F G \n",
        "Game 7 of 10,000 (0.0700%): O wins\n",
        "\"\"\""
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n __ _ _ _ _ _ __\\n1|  X X        |\\n2|  O O        |\\n3|  O X   X O X|\\n4|  O X   O X O|\\n5|O X O   X O O|\\n6|X O X   X O X|\\n -- - - - - - --\\n  A B C D E F G \\nGame 7 of 10,000 (0.0700%): O wins\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_P-Ykou4XivM",
        "colab_type": "code",
        "outputId": "13e60258-3baa-43db-df17-8d1f0e1aeaf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "source": [
        "board_state = empty_board()\n",
        "board_state[(0,0,2,2,2,3,3,4,4,5,5,5,5), (1,2,2,4,6,2,5,1,4,0,2,4,6)] = VALUE_X\n",
        "board_state[(1,1,2,2,3,3,3,4,4,4,4,5,5), (1,2,1,5,1,4,6,0,2,5,6,1,5)] = VALUE_O\n",
        "pprint(board_state)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " __ _ _ _ _ _ __\n",
            "1|  X X        |\n",
            "2|  O O        |\n",
            "3|  O X   X O X|\n",
            "4|  O X   O X O|\n",
            "5|O X O   X O O|\n",
            "6|X O X   X O X|\n",
            " -- - - - - - --\n",
            "  A B C D E F G \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PCQPQd8B-dJ",
        "colab_type": "code",
        "outputId": "c6aa2537-d0ff-409e-e2f5-ebbdf7d6722b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "game_over(board_state, (4, 0))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7u_7KE338vJs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode_feature(feature: torch.ByteTensor, check_inverted: bool=True) -> Tuple[int, bool]:\n",
        "  \"\"\"\n",
        "  Returns the encoding as well as a boolean value stating whether the feature\n",
        "  has been inverted.\n",
        "  \"\"\"\n",
        "  def encode_feature_without_inversion(feature: torch.ByteTensor) -> int:\n",
        "    offsets = 3 ** torch.LongTensor(list(range(feature.numel())))\n",
        "    return (feature * offsets.view(feature.size())).sum().item() - 1\n",
        "  \n",
        "  orig_encoding = encode_feature_without_inversion(feature)\n",
        "\n",
        "  if check_inverted:\n",
        "    inverted_feature = feature.clone()\n",
        "    inverted_feature[feature == VALUE_X] = VALUE_O\n",
        "    inverted_feature[feature == VALUE_O] = VALUE_X\n",
        "\n",
        "    inverted_encoding = encode_feature_without_inversion(inverted_feature)\n",
        "  else:\n",
        "    inverted_encoding = 1e21\n",
        "\n",
        "  if orig_encoding < inverted_encoding:\n",
        "    return orig_encoding, False\n",
        "  else:\n",
        "    return inverted_encoding, True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJUCjBMYPTUw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode_feature_li(feature: torch.ByteTensor) -> Tuple[int, bool, bool]:\n",
        "  \"\"\"\n",
        "  Returns the encoding as well as two boolean values stating whether the feature\n",
        "  has been flipped and/or inverted respectively.\n",
        "  \"\"\"\n",
        "  encoding, _ = encode_feature(feature, False)\n",
        "\n",
        "  flipped_feature = feature.flip(1)\n",
        "  encoding_flipped, _ = encode_feature(flipped_feature, False)\n",
        "  \n",
        "  inverted_feature = feature.clone()\n",
        "  inverted_feature[feature == VALUE_X] = VALUE_O\n",
        "  inverted_feature[feature == VALUE_O] = VALUE_X\n",
        "  encoding_inverted, _ = encode_feature(inverted_feature, False)\n",
        "\n",
        "  inverted_flipped_feature = flipped_feature.clone()\n",
        "  inverted_flipped_feature[flipped_feature == VALUE_X] = VALUE_O\n",
        "  inverted_flipped_feature[flipped_feature == VALUE_O] = VALUE_X\n",
        "  encoding_inverted_flipped, _ = encode_feature(inverted_flipped_feature, False)\n",
        "\n",
        "  encodings = [encoding,\n",
        "               encoding_flipped,\n",
        "               encoding_inverted,\n",
        "               encoding_inverted_flipped]\n",
        "\n",
        "  min_encoding_index = encodings.index(min(encodings))\n",
        "  flipped = min_encoding_index in [1, 3]\n",
        "  inverted = min_encoding_index in [2, 3]\n",
        "\n",
        "  return encodings[min_encoding_index], flipped, inverted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rqbCt7TtcHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def active_features(state: torch.ByteTensor) -> ActiveFeatures:\n",
        "  \"\"\"\n",
        "  Returns a list of encoded features.\n",
        "  Ignores all empty features.\n",
        "  \"\"\"\n",
        "  # It's relatively inexpensive to just return a list of tuples instead of a\n",
        "  # tree structure.\n",
        "  features = collections.Counter()\n",
        "  for feature_size in range(1, MAX_FEATURE_SIZE + 1):\n",
        "    for row in range(state.size()[0] - feature_size + 1):\n",
        "      cols_left = 4 - feature_size // 2\n",
        "      for col in range(cols_left):\n",
        "        feature = state[row : row + feature_size, col : col + feature_size]\n",
        "        # We do not care about totally blank features.\n",
        "        if (feature != VALUE_BLANK).any():\n",
        "          # Location independent feature.\n",
        "          encoding, _, inverted = encode_feature_li(feature)\n",
        "          features[(\n",
        "            feature_size - 1,\n",
        "            -1,\n",
        "            encoding,\n",
        "            1 - 2 * int(inverted),\n",
        "          )] += 1\n",
        "          # Location dependent feature.\n",
        "          encoding, inverted = encode_feature(feature)\n",
        "          features[(\n",
        "              feature_size - 1,\n",
        "              row,\n",
        "              col,\n",
        "              encoding,\n",
        "              1 - 2 * int(inverted),\n",
        "          )] += 1\n",
        "\n",
        "      flipped_state = state.flip(1)\n",
        "\n",
        "      cols_right = 4 - math.ceil(feature_size / 2)\n",
        "      for col in range(cols_right):\n",
        "        feature = flipped_state[row : row + feature_size, col : col + feature_size] \n",
        "        # We do not care about totally blank features.\n",
        "        if (feature != VALUE_BLANK).any():\n",
        "          # Location independent feature.\n",
        "          encoding, _, inverted = encode_feature_li(feature)\n",
        "          features[(\n",
        "              feature_size - 1,\n",
        "              -1,\n",
        "              encoding,\n",
        "              1 - 2 * int(inverted),\n",
        "          )] += 1\n",
        "          # Location dependent feature.\n",
        "          encoding, inverted = encode_feature(feature)\n",
        "          features[(\n",
        "              feature_size - 1,\n",
        "              row,\n",
        "              col,\n",
        "              encoding,\n",
        "              1 - 2 * int(inverted),\n",
        "          )] += 1\n",
        "          \n",
        "  return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPnm4i2lfSSy",
        "colab_type": "code",
        "outputId": "8d0f6909-c39f-4a6b-824a-1e3c53446ac8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "active_features(board_state)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({(0, -1, 0, -1): 13,\n",
              "         (0, -1, 0, 1): 13,\n",
              "         (0, 0, 1, 0, 1): 1,\n",
              "         (0, 0, 2, 0, 1): 1,\n",
              "         (0, 1, 1, 0, -1): 1,\n",
              "         (0, 1, 2, 0, -1): 1,\n",
              "         (0, 2, 0, 0, 1): 1,\n",
              "         (0, 2, 1, 0, -1): 2,\n",
              "         (0, 2, 2, 0, 1): 2,\n",
              "         (0, 3, 0, 0, -1): 1,\n",
              "         (0, 3, 1, 0, -1): 1,\n",
              "         (0, 3, 1, 0, 1): 1,\n",
              "         (0, 3, 2, 0, -1): 1,\n",
              "         (0, 3, 2, 0, 1): 1,\n",
              "         (0, 4, 0, 0, -1): 2,\n",
              "         (0, 4, 1, 0, -1): 1,\n",
              "         (0, 4, 1, 0, 1): 1,\n",
              "         (0, 4, 2, 0, -1): 1,\n",
              "         (0, 4, 2, 0, 1): 1,\n",
              "         (0, 5, 0, 0, 1): 2,\n",
              "         (0, 5, 1, 0, -1): 2,\n",
              "         (0, 5, 2, 0, 1): 2,\n",
              "         (1, -1, 8, 1): 1,\n",
              "         (1, -1, 9, -1): 2,\n",
              "         (1, -1, 9, 1): 2,\n",
              "         (1, -1, 10, -1): 4,\n",
              "         (1, -1, 10, 1): 3,\n",
              "         (1, -1, 40, -1): 1,\n",
              "         (1, -1, 43, -1): 1,\n",
              "         (1, -1, 44, 1): 2,\n",
              "         (1, -1, 45, -1): 1,\n",
              "         (1, -1, 48, -1): 2,\n",
              "         (1, -1, 49, 1): 2,\n",
              "         (1, -1, 51, 1): 6,\n",
              "         (1, 0, 0, 32, -1): 1,\n",
              "         (1, 0, 1, 43, -1): 1,\n",
              "         (1, 0, 2, 10, -1): 1,\n",
              "         (1, 1, 0, 29, -1): 1,\n",
              "         (1, 1, 0, 44, -1): 1,\n",
              "         (1, 1, 1, 44, 1): 1,\n",
              "         (1, 1, 1, 52, 1): 1,\n",
              "         (1, 1, 2, 8, 1): 1,\n",
              "         (1, 1, 2, 10, 1): 1,\n",
              "         (1, 2, 0, 29, -1): 1,\n",
              "         (1, 2, 0, 51, 1): 1,\n",
              "         (1, 2, 1, 49, 1): 1,\n",
              "         (1, 2, 1, 51, -1): 1,\n",
              "         (1, 2, 2, 9, 1): 1,\n",
              "         (1, 2, 2, 10, -1): 1,\n",
              "         (1, 3, 0, 42, -1): 1,\n",
              "         (1, 3, 0, 50, 1): 1,\n",
              "         (1, 3, 1, 51, -1): 1,\n",
              "         (1, 3, 1, 51, 1): 1,\n",
              "         (1, 3, 2, 10, -1): 1,\n",
              "         (1, 3, 2, 10, 1): 1,\n",
              "         (1, 4, 0, 48, -1): 1,\n",
              "         (1, 4, 0, 51, -1): 1,\n",
              "         (1, 4, 1, 49, 1): 1,\n",
              "         (1, 4, 1, 51, 1): 1,\n",
              "         (1, 4, 2, 9, 1): 1,\n",
              "         (1, 4, 2, 10, 1): 1,\n",
              "         (2, -1, 3644, 1): 1,\n",
              "         (2, -1, 3760, -1): 1,\n",
              "         (2, -1, 3783, -1): 1,\n",
              "         (2, -1, 3786, 1): 1,\n",
              "         (2, -1, 3787, 1): 1,\n",
              "         (2, -1, 3833, -1): 1,\n",
              "         (2, -1, 3838, 1): 2,\n",
              "         (2, -1, 3840, -1): 1,\n",
              "         (2, -1, 3864, 1): 1,\n",
              "         (2, -1, 7344, 1): 1,\n",
              "         (2, -1, 7605, 1): 1,\n",
              "         (2, -1, 8306, 1): 1,\n",
              "         (2, -1, 8541, 1): 1,\n",
              "         (2, -1, 10660, -1): 1,\n",
              "         (2, -1, 11663, 1): 1,\n",
              "         (2, -1, 11803, -1): 1,\n",
              "         (2, -1, 12145, 1): 1,\n",
              "         (2, -1, 12284, -1): 1,\n",
              "         (2, -1, 12291, 1): 1,\n",
              "         (2, 0, 0, 11594, 1): 1,\n",
              "         (2, 0, 0, 11663, 1): 1,\n",
              "         (2, 0, 1, 3644, 1): 1,\n",
              "         (2, 0, 1, 3864, 1): 1,\n",
              "         (2, 0, 2, 7344, 1): 1,\n",
              "         (2, 1, 0, 11363, 1): 1,\n",
              "         (2, 1, 0, 12284, -1): 1,\n",
              "         (2, 1, 1, 3787, 1): 1,\n",
              "         (2, 1, 1, 3833, -1): 1,\n",
              "         (2, 1, 2, 8559, -1): 1,\n",
              "         (2, 2, 0, 12251, -1): 1,\n",
              "         (2, 2, 0, 13029, 1): 1,\n",
              "         (2, 2, 1, 3838, 1): 1,\n",
              "         (2, 2, 1, 3840, -1): 1,\n",
              "         (2, 2, 2, 8541, 1): 1,\n",
              "         (2, 3, 0, 12145, 1): 1,\n",
              "         (2, 3, 0, 12299, 1): 1,\n",
              "         (2, 3, 1, 3786, 1): 1,\n",
              "         (2, 3, 1, 3838, 1): 1,\n",
              "         (2, 3, 2, 7605, 1): 1,\n",
              "         (3, -1, 8071025, -1): 1,\n",
              "         (3, -1, 8616471, 1): 1,\n",
              "         (3, -1, 8642549, -1): 1,\n",
              "         (3, -1, 8653958, -1): 1,\n",
              "         (3, -1, 8655188, 1): 1,\n",
              "         (3, -1, 9186695, 1): 1,\n",
              "         (3, -1, 17233996, 1): 1,\n",
              "         (3, -1, 17395996, 1): 1,\n",
              "         (3, -1, 18283346, 1): 1,\n",
              "         (3, -1, 18458692, 1): 1,\n",
              "         (3, -1, 18461060, -1): 1,\n",
              "         (3, -1, 18469546, -1): 1,\n",
              "         (3, 0, 0, 8071985, 1): 1,\n",
              "         (3, 0, 0, 8653958, -1): 1,\n",
              "         (3, 0, 1, 18283346, 1): 1,\n",
              "         (3, 0, 1, 18469546, -1): 1,\n",
              "         (3, 1, 0, 8642549, -1): 1,\n",
              "         (3, 1, 0, 9186695, 1): 1,\n",
              "         (3, 1, 1, 18458692, 1): 1,\n",
              "         (3, 1, 1, 18461060, -1): 1,\n",
              "         (3, 2, 0, 8616471, 1): 1,\n",
              "         (3, 2, 0, 8655188, 1): 1,\n",
              "         (3, 2, 1, 17233996, 1): 1,\n",
              "         (3, 2, 1, 17395996, 1): 1,\n",
              "         (4, -1, 339720848249, 1): 1,\n",
              "         (4, -1, 340792706078, 1): 1,\n",
              "         (4, -1, 361703842658, -1): 1,\n",
              "         (4, -1, 365171008790, 1): 1,\n",
              "         (4, -1, 490970587849, -1): 1,\n",
              "         (4, -1, 497143840035, -1): 1,\n",
              "         (4, 0, 0, 361703842658, -1): 1,\n",
              "         (4, 0, 0, 365171008790, 1): 1,\n",
              "         (4, 0, 1, 490970587849, -1): 1,\n",
              "         (4, 1, 0, 339720848249, 1): 1,\n",
              "         (4, 1, 0, 340792706078, 1): 1,\n",
              "         (4, 1, 1, 497143840035, -1): 1,\n",
              "         (5, -1, 88240535401018437, -1): 1,\n",
              "         (5, -1, 88287918865216536, -1): 1,\n",
              "         (5, 0, 0, 88240535401018437, -1): 1,\n",
              "         (5, 0, 0, 88287918865216536, -1): 1})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQX2iRItCGLt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(state: torch.ByteTensor,\n",
        "             last_move_pos: Tuple[int, int]) -> float:\n",
        "  if state is None or last_move_pos is None:\n",
        "    return 0.5\n",
        "\n",
        "  if game_over(state, last_move_pos):\n",
        "    return float(state[last_move_pos] == VALUE_X)\n",
        "  \n",
        "  features: ActiveFeatures = active_features(state)\n",
        "\n",
        "  accumulator = 0\n",
        "  for feature, count in features.items():\n",
        "    if len(feature) == 4: # Location independent.\n",
        "      try:\n",
        "        accumulator += count * weights[feature[0]][feature[1]][feature[2]] * feature[3]\n",
        "      except KeyError:\n",
        "        weights[feature[0]][feature[1]][feature[2]] = 0\n",
        "    else: # Location dependent.\n",
        "      try:\n",
        "        accumulator += count * weights[feature[0]][feature[1]][feature[2]][feature[3]] * feature[4]\n",
        "      except KeyError:\n",
        "        weights[feature[0]][feature[1]][feature[2]][feature[3]] = 0\n",
        "  \n",
        "  try:\n",
        "    return 1 / (1 + math.exp(-accumulator)) # Sigmoid to squash to [0.0, 1.0].\n",
        "  except OverflowError:\n",
        "    return 1.0 if accumulator > 0 else 0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6WHoAwoEnrz",
        "colab_type": "code",
        "outputId": "b5a20789-bcb0-4b33-8c3f-58fa0654421d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "evaluate(board_state, (5, 3))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqclOeBDfeue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def td_update(agent: \"Agent\",\n",
        "              new_state: torch.ByteTensor,\n",
        "              last_move_pos: Tuple[int, int],\n",
        "              learning_rate: float = LEARNING_RATE) -> float:\n",
        "  signal_power = sum([count * count for count in agent.prev_active_features.values()]) # This may need to be updated to utilize weight sharing for inversion-equivalent features.\n",
        "  afterstate_value = evaluate(new_state, last_move_pos)\n",
        "\n",
        "  for feature, count in agent.prev_active_features.items():\n",
        "    delta = learning_rate * count / signal_power * (afterstate_value - agent.prev_state_value)\n",
        "    if len(feature) == 4: # Location independent.\n",
        "      try:\n",
        "        weights[feature[0]][feature[1]][feature[2]] += delta * feature[3]\n",
        "      except KeyError:\n",
        "        weights[feature[0]][feature[1]][feature[2]] = delta * feature[3]\n",
        "    else: # Location dependent.\n",
        "      try:\n",
        "        weights[feature[0]][feature[1]][feature[2]][feature[3]] += delta * feature[4]\n",
        "      except KeyError:\n",
        "        weights[feature[0]][feature[1]][feature[2]][feature[3]] = delta * feature[4]\n",
        "\n",
        "  return afterstate_value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cdM8XzTR8Hn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def drop_piece(state: torch.ByteTensor,\n",
        "               column: int,\n",
        "               x_player: bool) -> Tuple[torch.ByteTensor, Tuple[int, int]]:\n",
        "  drop_row = state.size()[0] - 1 # In case entire column is empty.\n",
        "\n",
        "  for row in range(state.size()[0]):\n",
        "    if state[row, column] != VALUE_BLANK:\n",
        "      drop_row = row - 1\n",
        "      break\n",
        "  \n",
        "  new_state = state.clone()\n",
        "  new_state[drop_row, column] = VALUE_X if x_player else VALUE_O\n",
        "\n",
        "  return new_state, (drop_row, column)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-yg8_KAlEQS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Agent():\n",
        "\n",
        "  x_player: bool # X player will try to maximize reward, O player will try to\n",
        "                 # minimize reward.\n",
        "  prev_move_rollouts: int\n",
        "  prev_active_features: ActiveFeatures\n",
        "  prev_state_value: float\n",
        "\n",
        "  def __init__(self, x_player: bool):\n",
        "    self.x_player = x_player\n",
        "    self.prev_move_rollouts = 0\n",
        "    self.reset_prev_state()\n",
        "\n",
        "  def reset_prev_state(self):\n",
        "    self.prev_active_features = active_features(empty_board())\n",
        "    self.prev_state_value = evaluate(empty_board(), None)\n",
        "\n",
        "  def best_move(self,\n",
        "                state: torch.ByteTensor,\n",
        "                epsilon: float=0.15) -> Tuple[torch.ByteTensor, Tuple[int, int]]:\n",
        "    \"\"\"\n",
        "    Uses an epsilon-greedy method to select the best move, then performs a TD\n",
        "    update for the afterstate of each possible action evaluated.\n",
        "\n",
        "    Returns the afterstate of the selected action, its value estimate, and a\n",
        "    tuple of integers describing the location of the move chosen.\n",
        "    \"\"\"\n",
        "\n",
        "    possible_afterstates = [drop_piece(state, column, self.x_player) for\n",
        "                            column in\n",
        "                            range(state.size()[1]) if\n",
        "                            state[0, column] == VALUE_BLANK]\n",
        "\n",
        "    # Explore.\n",
        "    if choices((True, False), weights=[epsilon, 1.0-epsilon])[0]:\n",
        "      new_state, last_move_pos = choice(possible_afterstates)\n",
        "      self.prev_state_value = td_update(self, new_state, last_move_pos)\n",
        "    else: # Exploit.\n",
        "      afterstate_values = [td_update(self, new_state, last_move_pos) for\n",
        "                           new_state, last_move_pos in\n",
        "                           possible_afterstates]\n",
        "\n",
        "      optimum_value = max(afterstate_values + [0.0]) if self.x_player else min(afterstate_values + [1.0])\n",
        "      optimum_states = [possible_afterstates[i] for\n",
        "                        i, afterstate_value in\n",
        "                        enumerate(afterstate_values) if\n",
        "                        afterstate_value == optimum_value]\n",
        "      \n",
        "      self.prev_state_value = optimum_value\n",
        "      new_state, last_move_pos = choice(optimum_states)\n",
        "\n",
        "    self.prev_active_features = active_features(new_state)\n",
        "\n",
        "    return new_state, last_move_pos"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11Y7ho79Gc4S",
        "colab_type": "code",
        "outputId": "c2775274-77a7-4420-fd85-9c512fed4422",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "cellView": "form"
      },
      "source": [
        "#@title Self-Play Training\n",
        "\n",
        "games = 5#@param {type: \"number\"}\n",
        "epsilon = 0.2#@param {type: \"number\"}\n",
        "show_games = False#@param {type: \"boolean\"}\n",
        "\n",
        "x_player = Agent(True)\n",
        "o_player = Agent(False)\n",
        "\n",
        "def train_game(initial_state: torch.ByteTensor) -> float:\n",
        "  train_state = initial_state.clone()\n",
        "\n",
        "  x_player.reset_prev_state()\n",
        "  o_player.reset_prev_state()\n",
        "\n",
        "  last_move_pos = None\n",
        "\n",
        "  if show_games:\n",
        "    pprint(train_state)\n",
        "  while True:\n",
        "    if show_games:\n",
        "      print()\n",
        "    train_state, last_move_pos = x_player.best_move(\n",
        "      train_state,\n",
        "      epsilon=epsilon\n",
        "    )\n",
        "    if show_games:\n",
        "      pprint(train_state)\n",
        "    if game_over(train_state, last_move_pos):\n",
        "      return 1.0 # X wins.\n",
        "    if show_games:\n",
        "      print()\n",
        "\n",
        "    train_state, last_move_pos = o_player.best_move(\n",
        "      train_state,\n",
        "      epsilon=epsilon\n",
        "    )\n",
        "    if show_games:\n",
        "      pprint(train_state)\n",
        "    if game_over(train_state, last_move_pos):\n",
        "      return 0.0 # O wins.\n",
        "    if board_full(train_state):\n",
        "      return 0.5 # Draw.\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "if show_games:\n",
        "  for game in range(games):\n",
        "    result_statement = {\n",
        "      0.0: \"O wins\",\n",
        "      0.5: \"Draw\",\n",
        "      1.0: \"X wins\",\n",
        "    }[train_game(empty_board())]\n",
        "\n",
        "    print(f\"Game {game+1:,} of {games:,} ({(game+1)/games:.4%}): {result_statement}\")\n",
        "else:\n",
        "  with mp.Pool() as p:\n",
        "    for game, result in enumerate(p.imap_unordered(train_game, (empty_board() for _ in range(games)))):\n",
        "      result_statement = {\n",
        "        0.0: \"O wins\",\n",
        "        0.5: \"Draw\",\n",
        "        1.0: \"X wins\",\n",
        "      }[result]\n",
        "\n",
        "      print(f\"Game {game+1:,} of {games:,} ({(game+1)/games:.4%}): {result_statement}\")\n",
        "\n",
        "time_elapsed = time.time() - start_time\n",
        "print(f\"Played {games:,} games in {time_elapsed:,.2f} seconds.\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Game 1 of 5 (20.0000%): X wins\n",
            "Game 2 of 5 (40.0000%): X wins\n",
            "Game 3 of 5 (60.0000%): X wins\n",
            "Game 4 of 5 (80.0000%): X wins\n",
            "Game 5 of 5 (100.0000%): O wins\n",
            "Played 5 games in 5.54 seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCkoITJ01FSm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}