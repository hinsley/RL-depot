{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TDt3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPpczDx+oXCJxT99BtCH/at",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hinsley/RL-depot/blob/master/temporal-difference/TDt3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KpBr7z8Mj1L",
        "colab_type": "text"
      },
      "source": [
        "# TDt3\n",
        "\n",
        "Temporal difference learning model for tic-tac-toe\n",
        "\n",
        "Algorithm: TD(0) combined with $\\epsilon$-greedy policy improvement\n",
        "\n",
        "Inspired by [Sutton & Barto - Reinforcement Learning: An Introduction](http://incompleteideas.net/book/the-book-2nd.html)\n",
        "\n",
        "Learns entirely from self-play"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNBxbqZsZZpA",
        "colab_type": "text"
      },
      "source": [
        "Board position encodings:\n",
        "\n",
        "$\\begin{bmatrix}0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8\\end{bmatrix} \\to \\begin{pmatrix} 0 & 1 & 2 \\\\ 3 & 4 & 5 \\\\ 6 & 7 & 8 \\end{pmatrix}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hc_AKD_-MfQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from time import time\n",
        "from typing import Dict, List, Optional, Tuple"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHiRIb0oRmUu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ActionValue = Optional[float] # [0.0, 1.0]. Higher values are better.\n",
        "\n",
        "PositionState = int # Enumeration. See below.\n",
        "VALUE_BLANK = 0\n",
        "VALUE_X = 1\n",
        "VALUE_O = 2\n",
        "\n",
        "BoardState = List[PositionState] # (3 x 3)\n",
        "\n",
        "EncodedBoardState = int # Trinary encoding."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97bcfMuthH-k",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title f_eq(a: float, b: float, epsilon: float=1e-4) -> bool\n",
        "def f_eq(a: float, b: float, epsilon: float=1e-4) -> bool:\n",
        "  \"\"\" Test for float equivalency. Parameterizes rounding error tolerance. \"\"\"\n",
        "\n",
        "  return abs(a - b) < epsilon"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd9qpInXSPpx",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title eval_state(state: BoardState, x_player: bool) -> ActionValue\n",
        "def eval_state(state: BoardState, x_player: bool) -> ActionValue:\n",
        "  \"\"\"\n",
        "  Used to generate a fresh action value. Only evaluates win/lose/draw\n",
        "  conditions, outputting a 0.5 action value if the state does not signify the\n",
        "  end of a game.\n",
        "\n",
        "  Because it is not possible in Tic-Tac-Toe to achieve a board state such that\n",
        "  both players have three moves in a row [sic], we can stop evaluating once the\n",
        "  first row [sic] is detected.\n",
        "  \"\"\"\n",
        "  \n",
        "  for group in [\n",
        "    [0,1,2], # Rows\n",
        "    [3,4,5],\n",
        "    [6,7,8],\n",
        "    [0,3,6], # Columns\n",
        "    [1,4,7],\n",
        "    [2,5,8],\n",
        "    [0,4,8], # Diagonals\n",
        "    [2,4,6],\n",
        "  ]:\n",
        "    if state[group[0]] == state[group[1]] == state[group[2]]:\n",
        "      try:\n",
        "        return {\n",
        "          VALUE_X: 1.0 if x_player else 0.0,\n",
        "          VALUE_O: 0.0 if x_player else 1.0,\n",
        "        }[state[group[0]]]\n",
        "      except KeyError: # Row of blanks\n",
        "        continue\n",
        "  \n",
        "  if any([position == VALUE_BLANK for position in state]):\n",
        "    return 0.5 # Board contains an empty space and no win condition achieved\n",
        "  else:\n",
        "    return 0.75 # Draw"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iddJu6sDsKsz",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title encode_board(state: BoardState) -> EncodedBoardState\n",
        "def encode_board(state: BoardState) -> EncodedBoardState:\n",
        "  \"\"\"\n",
        "  Encode a trinary board state into a single hashable value. Smallest position\n",
        "  is top left.\n",
        "  \"\"\"\n",
        "\n",
        "  return sum([value * 3 ** i for i, value in enumerate(state)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHFnimIup2Gb",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title decode_board(encoded_state: EncodedBoardState) -> BoardState\n",
        "def decode_board(encoded_state: EncodedBoardState) -> BoardState:\n",
        "  \"\"\"\n",
        "  Decode a single hashable representation of board state into an indexable\n",
        "  serialization of positions.\n",
        "  \"\"\"\n",
        "\n",
        "  return [encoded_state // (3 ** i) % 3 for i in range(9)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biOXEeiq2DdH",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title pprint(state: Optional[BoardState])\n",
        "def pprint(state: BoardState):\n",
        "  \"\"\" Pretty prints a board state. \"\"\"\n",
        "  \n",
        "  if state is None:\n",
        "    return\n",
        "\n",
        "  def graphical_position_state(position_state: PositionState) -> str:\n",
        "    return {\n",
        "        VALUE_BLANK: \"-\",\n",
        "        VALUE_X: \"X\",\n",
        "        VALUE_O: \"O\",\n",
        "    }[position_state]\n",
        "  \n",
        "  print()\n",
        "  print(*[graphical_position_state(pstate) for pstate in state[:3]])\n",
        "  print(*[graphical_position_state(pstate) for pstate in state[3:6]])\n",
        "  print(*[graphical_position_state(pstate) for pstate in state[6:]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRyoAYwbvPXD",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title class ActionEvaluator()\n",
        "\n",
        "from random import choice, choices\n",
        "\n",
        "class ActionEvaluator():\n",
        "\n",
        "  _action_values: Dict[EncodedBoardState, ActionValue]\n",
        "  _prev_state: EncodedBoardState\n",
        "  _x_player: bool\n",
        "\n",
        "\n",
        "  def __init__(self, x_player: bool=True):\n",
        "\n",
        "    self._action_values = {0: 0.5}\n",
        "    self.reset_board_state()\n",
        "    self._x_player = x_player\n",
        "  \n",
        "\n",
        "  def reset_board_state(self):\n",
        "\n",
        "    self._prev_state = encode_board([VALUE_BLANK] * 9)\n",
        "\n",
        "\n",
        "  def evaluate(self, state: BoardState) -> ActionValue:\n",
        "\n",
        "    encoded_state = encode_board(state)\n",
        "\n",
        "    if not encoded_state in self._action_values: # Unexplored action.\n",
        "      self._action_values[encoded_state] = eval_state(state, self._x_player)\n",
        "    \n",
        "    return self._action_values[encoded_state]\n",
        "\n",
        "\n",
        "  def back_up_value(self,\n",
        "                    new_state: BoardState,\n",
        "                    learning_rate: float=0.25):\n",
        "    \n",
        "    self._action_values[self._prev_state] += learning_rate * (self.evaluate(new_state) - self.evaluate(decode_board(self._prev_state)))\n",
        "    self._prev_state = encode_board(new_state)\n",
        "\n",
        "\n",
        "  def best_move(self, state: BoardState, beta: float) -> BoardState:\n",
        "\n",
        "    possible_states = []\n",
        "\n",
        "    for i, position_value in enumerate(state):\n",
        "      if position_value == VALUE_BLANK:\n",
        "        state_after_move = state.copy()\n",
        "        state_after_move[i] = (VALUE_X if self._x_player else VALUE_O)\n",
        "        possible_states.append(state_after_move)\n",
        "    \n",
        "    # Exploitation-Exploration selection (for training purposes).\n",
        "    if choices([True, False], weights=[beta, 1.0-beta])[0]:\n",
        "      return choice(possible_states)\n",
        "\n",
        "    max_action_value, argmax = 0.0, []\n",
        "    for new_state in possible_states:\n",
        "      action_value = self.evaluate(new_state)\n",
        "      if action_value >= max_action_value: # Found a better/equal move!\n",
        "        if action_value != max_action_value:\n",
        "          argmax = []\n",
        "        max_action_value = action_value\n",
        "        argmax.append(new_state)\n",
        "      if f_eq(max_action_value, 1.0): # No point in looking for a better move.\n",
        "        break\n",
        "\n",
        "    # We never have to worry about accessing an empty list here, as that means\n",
        "    # we've already reached a draw.\n",
        "\n",
        "    return choice(argmax)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmPKzx5u_5mv",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title move(x_player: ActionEvaluator, o_player: ActionEvaluator, state: BoardState, x_move: bool, beta: float=0.0) -> bool\n",
        "def move(x_player: ActionEvaluator, o_player: ActionEvaluator, state: BoardState, x_move: bool, beta: float=0.0) -> bool:\n",
        "  \"\"\"\n",
        "  Makes the best known move in place.\n",
        "  \n",
        "  Returns a boolean: True if game is over, False otherwise.\n",
        "  \"\"\"\n",
        "\n",
        "  player = (x_player if x_move else o_player)\n",
        "\n",
        "  prev_state = state.copy()\n",
        "  state[:] = player.best_move(state, beta)\n",
        "\n",
        "  if x_move:\n",
        "    x_player.back_up_value(state)\n",
        "  else:\n",
        "    o_player.back_up_value(state)\n",
        "\n",
        "  state_value = eval_state(state, x_move)\n",
        "  game_over = False\n",
        "  if f_eq(1.0, state_value):\n",
        "    if x_move:\n",
        "      print(\"X wins!\")\n",
        "      o_player.back_up_value(state)\n",
        "    else:\n",
        "      print(\"O wins!\")\n",
        "      x_player.back_up_value(state)\n",
        "    game_over = True\n",
        "  elif f_eq(0.75, state_value):\n",
        "    print(\"Draw!\")\n",
        "    if x_move:\n",
        "      o_player.back_up_value(state)\n",
        "    else:\n",
        "      x_player.back_up_value(state)\n",
        "    game_over = True\n",
        "  \n",
        "  if game_over:\n",
        "    x_player.reset_board_state()\n",
        "    o_player.reset_board_state()\n",
        "\n",
        "  return game_over"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRdbBB2P8jW5",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title move_o(x_player: ActionEvaluator, state: BoardState, row: int, col: int) -> bool\n",
        "def move_o(x_player: ActionEvaluator, o_player: ActionEvaluator, state: BoardState, row: int, col: int) -> bool:\n",
        "  \"\"\"\n",
        "  Makes a move for O in place. Row and col are zero-indexed.\n",
        "  \n",
        "  Returns a boolean stating whether the game is over. True if so, False if not.\n",
        "  \"\"\"\n",
        "  \n",
        "  if state[row * 3 + col] != VALUE_BLANK:\n",
        "    print(\"That's not valid -- someone has already moved there!\")\n",
        "    return\n",
        "\n",
        "  prev_state = state.copy()\n",
        "  state[row * 3 + col] = VALUE_O\n",
        "\n",
        "  game_over = eval_state(state, x_player=True) == 0.0\n",
        "\n",
        "  if game_over:\n",
        "    print(\"O wins!\")\n",
        "    x_player.back_up_value(state)\n",
        "    o_player.back_up_value(state)\n",
        "    x_player.reset_board_state()\n",
        "    o_player.reset_board_state()\n",
        "  else:\n",
        "    o_player.back_up_value(state)\n",
        "\n",
        "  return game_over"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yx9uEWm6OUke",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Training by Self-Play\n",
        "\n",
        "x_player = ActionEvaluator(x_player=True)\n",
        "o_player = ActionEvaluator(x_player=False)\n",
        "\n",
        "verbose = False\n",
        "\n",
        "games = 750 #@param {type: \"number\"}\n",
        "start_time = time()\n",
        "for game in range(games):\n",
        "  board_state = [VALUE_BLANK] * 9\n",
        "  if verbose:\n",
        "    pprint(board_state)\n",
        "  game_over = False\n",
        "  while True:\n",
        "    if verbose:\n",
        "      print()\n",
        "    game_over = move(x_player, o_player, board_state, x_move=True, beta=0.1)\n",
        "    if verbose:\n",
        "      pprint(board_state)\n",
        "    if game_over:\n",
        "      break\n",
        "    if verbose:\n",
        "      print()\n",
        "    game_over = move(x_player, o_player, board_state, x_move=False, beta=0.1)\n",
        "    if verbose:\n",
        "      pprint(board_state)\n",
        "    if game_over:\n",
        "      break\n",
        "time_elapsed = time() - start_time\n",
        "\n",
        "print(f\"Played {games:,} games in {time_elapsed:.2f} seconds.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEH1wGujzLZw",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Play!\n",
        "\n",
        "#@markdown Game restarts automatically -- just re-run the cell once a game ends.\n",
        "\n",
        "row =  \"Middle\"#@param [\"Top\", \"Middle\", \"Bottom\"]\n",
        "column =  \"Middle\"#@param [\"Left\", \"Middle\", \"Right\"]\n",
        "\n",
        "row = {\n",
        "    \"Top\": 0,\n",
        "    \"Middle\": 1,\n",
        "    \"Bottom\": 2,\n",
        "}[row]\n",
        "\n",
        "column = {\n",
        "    \"Left\": 0,\n",
        "    \"Middle\": 1,\n",
        "    \"Right\": 2,\n",
        "}[column]\n",
        "\n",
        "try:\n",
        "  turn = turn\n",
        "except:\n",
        "  turn = 1\n",
        "\n",
        "print(f\"Turn {turn}\")\n",
        "\n",
        "if turn == 1:\n",
        "  board_state = [VALUE_BLANK] * 9\n",
        "  move(x_player, None, board_state, x_move=True)\n",
        "  turn += 1\n",
        "else:\n",
        "  if not move_o(x_player, o_player, board_state, row, column):\n",
        "    if not move(x_player, o_player, board_state, x_move=True):\n",
        "      turn += 1\n",
        "    else:\n",
        "      turn = 1\n",
        "      row = \"\"\n",
        "  else:\n",
        "    turn = 1\n",
        "    column = \"\"\n",
        "\n",
        "pprint(board_state)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJlUuU_a8wYP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}